{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Using Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# creating enumerations using class \n",
    "#here it is associated with sentiment \n",
    "class Sentiment:\n",
    "    Negative = 'NEGATIVE'\n",
    "    Neutral = 'NEUTRAL'\n",
    "    Positive = 'POSITIVE' \n",
    "        \n",
    "class Review:\n",
    "    def __init__(self, text, score):\n",
    "        self.text = text\n",
    "        self.score = score\n",
    "        self.sentiment = self.get_sentiment()\n",
    "    \n",
    "    def get_sentiment(self):\n",
    "        if self.score <= 2:\n",
    "            return Sentiment.Negative\n",
    "        elif self.score == 3:\n",
    "            return Sentiment.Neutral\n",
    "        else:\n",
    "            return Sentiment.Positive\n",
    "        \n",
    "class ReviewContainer:\n",
    "    def __init__(self,reviews):\n",
    "        self.reviews = reviews\n",
    "    \n",
    "    def evenly_distribute(self):\n",
    "        negative = list(filter(lambda x : x.sentiment == Sentiment.Negative, self.reviews))\n",
    "        positive = list(filter(lambda x : x.sentiment == Sentiment.Positive, self.reviews))\n",
    "        neutral = list(filter(lambda x : x.sentiment == Sentiment.Neutral, self.reviews))\n",
    "        positive_shrunk = positive[:len(negative)]\n",
    "        self.reviews = negative + positive_shrunk \n",
    "        random.shuffle(self.reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "#productReview.json contains 10261 reviews of products sold through Amazon\n",
    "file_name='./productReview.json'\n",
    "\n",
    "reviews=[]\n",
    "\n",
    "with open(file_name,encoding='utf-8-sig') as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line)\n",
    "        #Creating a list of objects instead of just appending data to list, making it simpler for data handling.\n",
    "        reviews.append(Review(review['reviewText'],review['overall']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624\n",
      "310\n"
     ]
    }
   ],
   "source": [
    "#Spliting into train and test dataset using ‘train_test_split’ class \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#'test size' parameter decides the size of the data that has to be split as the test dataset here it is 0.03 i.e 33%. \n",
    "#'random_state=42' parameter ensures the result would be the same each time in train and test datasets while executing code.\n",
    "\n",
    "training, test = train_test_split(reviews,test_size=0.33,random_state=42)\n",
    "\n",
    "train_data= ReviewContainer(training)\n",
    "test_data= ReviewContainer(test)\n",
    "train_data.evenly_distribute()\n",
    "test_data.evenly_distribute()\n",
    "\n",
    "print(len(train_data.reviews))\n",
    "print(len(test_data.reviews))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features \n",
    "train_x=[x.text for x in train_data.reviews]\n",
    "train_y=[x.sentiment for x in train_data.reviews]\n",
    "#labels \n",
    "test_x=[x.text for x in test_data.reviews]\n",
    "test_y=[x.sentiment for x in test_data.reviews]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bags of Words Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With drum pads, I basically either get 0 velocity, or max.  And I have to really hammer on them to trigger.  Hurts after a while.Likes:+ Size+ Assignable knobs.+ Works good w/ Ableton LiveDislikes:- Drum pads!Keys are pretty cheesy but workable and expected for this price and size.I'm looking to upgrade after a month.. Want better drum pads.  :-/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Formatting text document to matrix of token counts and TF-IDF features.\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "#Learn the vocabulary dictionary and return term-document matrix.\n",
    "train_x_vec=vectorizer.fit_transform(train_x) \n",
    "\n",
    "#Transform documents to document-term matrix.\n",
    "test_x_vec=vectorizer.transform(test_x)\n",
    "                                        \n",
    "print(train_x[0])\n",
    "train_x_vec.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf_svm=svm.SVC(kernel='linear')\n",
    "clf_svm.fit(train_x_vec,train_y)\n",
    "predicted_svm = clf_svm.predict(test_x_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Linear SVM is : 0.8032258064516129\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Linear SVM is :' , accuracy_score(test_y,predicted_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of Linear SVM is : [0.79322034 0.81230769]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print('F1 score of Linear SVM is :',f1_score(test_y,predicted_svm,average=None,labels=[Sentiment.Positive,Sentiment.Negative]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realtime Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking_input = input('Enter the string :')\n",
    "#checking_input=[checking_input]\n",
    "#check_transform= vectorizer.transform(checking_input)\n",
    "#print('The input statement is :',clf_svm.predict(check_transform))\n",
    "#clf_svm.predict(vectorizer.transform([\"happy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "file = open('SentimentAnalysis_predict.pkl','wb')\n",
    "pickle.dump(clf_svm,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('SentimentAnalysis_transform.pkl','wb')\n",
    "pickle.dump(vectorizer,file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
